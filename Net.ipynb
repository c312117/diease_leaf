{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep  2 10:39:59 2020\n",
    "\n",
    "@author: c3121\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#%%\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_mask(hsv,img,low,high):\n",
    "    # Apply color mask to image\n",
    "    mask = cv2.inRange(hsv, low, high)\n",
    "    res = cv2.bitwise_and(img,img, mask= mask)\n",
    "    return res\n",
    "\n",
    "#%%\n",
    "\n",
    "base_path = r'diease'#這裡要改\n",
    "img_1=[]\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".JPG\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            file_size = os.path.getsize(filename)\n",
    "            category_name = os.path.basename(root)\n",
    "            #print(filename)\n",
    "            if file_size >= 2048:\n",
    "                #print(filename)\n",
    "                im = cv2.imread(filename)\n",
    "                #print(filename)\n",
    "                #im = cv2.imread(r'diease/c47ccf21-5249-4a95-8d33-0d640e3529f7___RS_L.Scorch 0158.JPG')\n",
    "                im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "                img_1.append(im)\n",
    "img_1_array=np.asarray(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立model_...Net\n",
    "from keras.models import Model  \n",
    "from keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate  \n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D,AveragePooling2D  \n",
    "import numpy as np  \n",
    "seed = 7  \n",
    "np.random.seed(seed)  \n",
    "  \n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1),name=None):  \n",
    "    if name is not None:  \n",
    "        bn_name = name + '_bn'  \n",
    "        conv_name = name + '_conv'  \n",
    "    else:  \n",
    "        bn_name = None  \n",
    "        conv_name = None  \n",
    "  \n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)  \n",
    "    x = BatchNormalization(axis=3,name=bn_name)(x)  \n",
    "    return x  \n",
    "  \n",
    "def Inception(x,nb_filter):  \n",
    "    branch1x1 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)  \n",
    "  \n",
    "    branch3x3 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)  \n",
    "    branch3x3 = Conv2d_BN(branch3x3,nb_filter,(3,3), padding='same',strides=(1,1),name=None)  \n",
    "  \n",
    "    branch5x5 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)  \n",
    "    branch5x5 = Conv2d_BN(branch5x5,nb_filter,(1,1), padding='same',strides=(1,1),name=None)  \n",
    "  \n",
    "    branchpool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)  \n",
    "    branchpool = Conv2d_BN(branchpool,nb_filter,(1,1),padding='same',strides=(1,1),name=None)  \n",
    "  \n",
    "    x = concatenate([branch1x1,branch3x3,branch5x5,branchpool],axis=3)  \n",
    "  \n",
    "    return x  \n",
    "  \n",
    "inpt = Input(shape=(224,224,3))  \n",
    "#padding = 'same',填充為(步長-1)/2,還可以用ZeroPadding2D((3,3))  \n",
    "x = Conv2d_BN(inpt,64,(7,7),strides=(2,2),padding='same')  \n",
    "x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)  \n",
    "x = Conv2d_BN(x,192,(3,3),strides=(1,1),padding='same')  \n",
    "x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)  \n",
    "x = Inception(x,64)#256  \n",
    "x = Inception(x,120)#480  \n",
    "x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)  \n",
    "x = Inception(x,128)#512  \n",
    "x = Inception(x,128)  \n",
    "x = Inception(x,128)  \n",
    "x = Inception(x,132)#528  \n",
    "x = Inception(x,208)#832  \n",
    "x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)  \n",
    "x = Inception(x,208)  \n",
    "x = Inception(x,256)#1024  \n",
    "x = AveragePooling2D(pool_size=(7,7),strides=(7,7),padding='same')(x)  \n",
    "x = Dropout(0.4)(x)  \n",
    "x = Dense(1000,activation='relu')(x)  \n",
    "x = Dense(1000,activation='softmax')(x)  \n",
    "model = Model(inpt,x,name='inception')  \n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])  \n",
    "model.summary()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用model\n",
    "from keras.models import load_model   \n",
    "#選用model\n",
    "model_fcnn=load_model('fcnn.h5')\n",
    "n=0\n",
    "for im in img_1_array:\n",
    "    #im = cv2.imread('diease/01cff44f-9564-42f7-9a29-3daa487b306a___RS_L.Scorch 1333.JPG')\n",
    "    #im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "    #im=im.astype('float32')/255\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "    imOut=im.copy()\n",
    "    im=im.astype('float32')/255\n",
    "\n",
    "    im=im.reshape(-1,128,128,3)\n",
    "    pred=model_fcnn.predict(im)\n",
    "\n",
    "    #print(pred)\n",
    "    #原本顏色太暗所以條遺下\n",
    "    pred=pred.astype('float32')\n",
    "    predOut =pred*255\n",
    "    predOut = predOut.astype(np.uint8)\n",
    "    #\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(cv2.cvtColor(predOut[0],cv2.COLOR_BGR2RGB))\n",
    "    #存檔先註解\n",
    "    #cv2.imwrite('step1_2/cnn_{}.jpg'.format(n),predOut[0])\n",
    "    #plt.subplot(2,2,2)\n",
    "    #plt.imshow(cv2.cvtColor(pred[0],cv2.COLOR_BGR2RGB))\n",
    "    #mask=np.zeros((128,128),dtype=np.uint8)\n",
    "    for x in  range(128):\n",
    "        for y in range(128):\n",
    "            if(pred[0][x][y][1]>0.3):   \n",
    "                pred[0][x][y]=(0,0,0)\n",
    "            else:\n",
    "                imOut[x][y]=(0,0,255)\n",
    "    #存檔先註解\n",
    "    #cv2.imwrite('step1_3/cnn_diease_{}.jpg'.format(n),imOut)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(cv2.cvtColor(imOut,cv2.COLOR_BGR2RGB))            \n",
    "    #print(pred)\n",
    "    #pred=pred.astype('float32')\n",
    "    #pred=cv2.cvtColor(pred.reshape(128,128,3),cv2.COLOR_BGR2RGB)\n",
    "    #plt.subplot(2,2,2)\n",
    "    #plt.imshow(pred)\n",
    "    #plt.subplot(2,2,3)\n",
    "    #plt.imshow(mask,cmap='gray')\n",
    "    #print(imOut.dtype)\n",
    "    \n",
    "    #ret,mask = cv2.threshold(mask,55,255,cv2.THRESH_BINARY)\n",
    "    #print(mask.dtype)\n",
    "    #im_res= cv2.bitwise_and(imOut,imOut, mask= mask)\n",
    "    #plt.subplot(2,2,4)\n",
    "    \n",
    "    #plt.imshow(cv2.cvtColor(im_res,cv2.COLOR_BGR2RGB))       \n",
    "    plt.show()\n",
    "    #cv2.imwrite('cnn_diease/cnn_diease_{}.jpg'.format(n),im_res)\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-tf-venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
