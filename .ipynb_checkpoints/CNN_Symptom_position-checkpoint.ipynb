{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep  2 10:39:59 2020\n",
    "\n",
    "@author: c3121\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#%%\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#選用編號1的GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#將diease資料夾中的圖檔調整為大小128*128並全部存到img_1_array的array中\n",
    "base_path = r'diease'#這裡要改\n",
    "img_1=[]\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".JPG\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            file_size = os.path.getsize(filename)\n",
    "            category_name = os.path.basename(root)\n",
    "            #print(filename)\n",
    "            if file_size >= 2048:\n",
    "                #print(filename)\n",
    "                im = cv2.imread(filename)\n",
    "                im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "                img_1.append(im)\n",
    "img_1_array=np.asarray(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SpatialDropout2D, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#自己修的model\n",
    "model_cnn = Sequential()\n",
    "from keras.models import load_model   \n",
    "    #First Convolution\n",
    "model_cnn.add(Conv2D(96,(3,3),strides=(2,2),input_shape=(128,128,3),padding='same',activation='relu'))  \n",
    "    #Second Convolution \n",
    "model_cnn.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "    #Two Convolution layer \n",
    "model_cnn.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_cnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "    #One Transposed Convolution layer and three Convolution layer\n",
    "model_cnn.add(Conv2DTranspose(32,(3,3),strides=(2,2),padding='same',activation='relu'))\n",
    "model_cnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_cnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_cnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "    #Classfication layer\n",
    "model_cnn.add(Conv2D(3,(3,3),strides=(1,1),padding='same',activation='softmax'))\n",
    "    \n",
    "\n",
    "model_cnn.summary()\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model_cnn.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原始的AlexNet 單純放上來比較 輸出為其layer配置\n",
    "model_Alex = Sequential()\n",
    "  \n",
    "\n",
    " #First Convolution and Pooling layer\n",
    "model_Alex.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(128,128,3),padding='valid',activation='relu'))\n",
    "model_Alex.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "  \n",
    "\n",
    "  \n",
    "    #Second Convolution and Pooling layer\n",
    "model_Alex.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu'))\n",
    "model_Alex.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    \n",
    "\n",
    "    #Three Convolution layer and Pooling Layer\n",
    "model_Alex.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_Alex.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_Alex.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_Alex.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    \n",
    "\n",
    "    #Fully connection layer\n",
    "model_Alex.add(Flatten())\n",
    "model_Alex.add(Dense(4096,activation='relu'))\n",
    "model_Alex.add(Dropout(0.5))\n",
    "model_Alex.add(Dense(4096,activation='relu'))\n",
    "model_Alex.add(Dropout(0.5))\n",
    "model_Alex.add(Dense(1000,activation='relu'))\n",
    "model_Alex.add(Dropout(0.5))\n",
    "   \n",
    "    #Classfication layer\n",
    "model_Alex.add(Dense(2,activation='softmax'))\n",
    "model_Alex.summary()\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model_Alex.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "#print(len(img_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練\n",
    "history=model_cnn.fit(img_1_array,img_1_array , batch_size=32, epochs=50,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練過程可視化\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用model\n",
    "from keras.models import load_model   \n",
    "#選用model\n",
    "#model_cnn=load_model('fcnn.h5')\n",
    "n=0\n",
    "for im in img_1_array[:10]:\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))\n",
    "    imOut=im.copy()\n",
    "    im=im.astype('float32')/255\n",
    "    im=im.reshape(-1,128,128,3)\n",
    "    pred=model_cnn.predict(im)\n",
    "    pred=pred.astype('float32')\n",
    "    predOut =pred*255\n",
    "    predOut = predOut.astype(np.uint8)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(cv2.cvtColor(predOut[0],cv2.COLOR_BGR2RGB))\n",
    "    #存檔先註解\n",
    "    #cv2.imwrite('step1_2/cnn_{}.jpg'.format(n),predOut[0])\n",
    "    for x in  range(128):\n",
    "        for y in range(128):\n",
    "            if(pred[0][x][y][1]>0.3):   \n",
    "                pred[0][x][y]=(0,0,0)\n",
    "            else:\n",
    "                imOut[x][y]=(0,0,255)\n",
    "    #存檔先註解\n",
    "    #cv2.imwrite('step1_3/cnn_diease_{}.jpg'.format(n),imOut)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(cv2.cvtColor(imOut,cv2.COLOR_BGR2RGB))               \n",
    "    plt.show()\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-tf-venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
