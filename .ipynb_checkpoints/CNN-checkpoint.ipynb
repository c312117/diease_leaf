{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep  2 10:39:59 2020\n",
    "\n",
    "@author: c3121\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#%%\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_mask(hsv,img,low,high):\n",
    "    # Apply color mask to image\n",
    "    mask = cv2.inRange(hsv, low, high)\n",
    "    res = cv2.bitwise_and(img,img, mask= mask)\n",
    "    return res\n",
    "\n",
    "#%%\n",
    "base_path = r'health'#這裡要改\n",
    "img_0=[]\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".JPG\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            file_size = os.path.getsize(filename)\n",
    "            category_name = os.path.basename(root)\n",
    "            if file_size >= 2048:\n",
    "                #print(filename)\n",
    "                im = cv2.imread(filename)\n",
    "                #im = cv2.imread(r'diease/c47ccf21-5249-4a95-8d33-0d640e3529f7___RS_L.Scorch 0158.JPG')\n",
    "                im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "                img_0.append(im)\n",
    "img_0_array=np.asarray(img_0)\n",
    "img_0_label=np.ones(img_0_array.shape[0])*0 \n",
    "base_path = r'diease'#這裡要改\n",
    "img_1=[]\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".JPG\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            file_size = os.path.getsize(filename)\n",
    "            category_name = os.path.basename(root)\n",
    "            #print(filename)\n",
    "            if file_size >= 2048:\n",
    "                #print(filename)\n",
    "                im = cv2.imread(filename)\n",
    "                #print(filename)\n",
    "                #im = cv2.imread(r'diease/c47ccf21-5249-4a95-8d33-0d640e3529f7___RS_L.Scorch 0158.JPG')\n",
    "                im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "                img_1.append(im)\n",
    "img_1_array=np.asarray(img_1)\n",
    "img_1_label=np.ones(img_1_array.shape[0])*1\n",
    "img_array=np.concatenate((img_0_array,img_1_array) ,axis=0)\n",
    "img_label=np.concatenate((img_0_label,img_1_label),axis=0)\n",
    "img_label = keras.utils.to_categorical(img_label, num_classes =2)\n",
    "#print(img_label)\n",
    "import random\n",
    "temp_img = list(zip(img_array, img_label))\n",
    "random.shuffle(temp_img)\n",
    "img_array, img_label = zip(*temp_img)\n",
    "img_array=np.asarray(img_array)\n",
    "img_label=np.asarray(img_label)\n",
    "print(img_label)\n",
    "print(img_label[1500:1600])\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_train,img_test,label_train,label_test=train_test_split(img_array, img_label, test_size=0.2,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SpatialDropout2D, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "model = Sequential()\n",
    "  \n",
    "\n",
    " #First Convolution and Pooling layer\n",
    "model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(128,128,3),padding='valid',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "  \n",
    "\n",
    "  \n",
    "    #Second Convolution and Pooling layer\n",
    "model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    \n",
    "\n",
    "    #Three Convolution layer and Pooling Layer\n",
    "model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    \n",
    "\n",
    "    #Fully connection layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "   \n",
    "    #Classfication layer\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.summary()\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "print(len(img_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(img_train, label_train, batch_size=64, epochs=100,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for index in range(len(img_test)):\n",
    "    test_im=img_test[index]\n",
    "   #plt.subplot(2,4,index+1)\n",
    "    #plt.imshow(cv2.cvtColor(test_im, cv2.COLOR_BGR2RGB))\n",
    "    test_im=test_im.reshape(-1,128,128,3)\n",
    "    pred=model.predict(test_im)\n",
    "    \n",
    "    a=np.argmax(pred)\n",
    "    b=np.argmax(label_test[index])\n",
    "    if(a==b):\n",
    "        n=n+1\n",
    "    #plt.show()\n",
    "print('準確:',n,'總共:' ,len(img_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fcnn = Sequential()\n",
    "from keras.models import load_model   \n",
    "#model_train=load_model('cnn.h5')\n",
    " #First Convolution and Pooling layer\n",
    "model_fcnn.add(Conv2D(96,(3,3),strides=(2,2),input_shape=(128,128,3),padding='same',activation='relu'))\n",
    "#model_fcnn.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same'))\n",
    "  \n",
    "\n",
    "  \n",
    "    #Second Convolution and Pooling layer\n",
    "model_fcnn.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_fcnn.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same'))\n",
    "    \n",
    "\n",
    "    #Three Convolution layer and Pooling Layer\n",
    "model_fcnn.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_fcnn.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_fcnn.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_fcnn.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_fcnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_fcnn.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same'))\n",
    "    \n",
    "\n",
    "    #Fully cnn layer\n",
    "model_fcnn.add(Conv2DTranspose(32,(3,3),strides=(2,2),padding='same',activation='relu'))\n",
    "model_fcnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_fcnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "model_fcnn.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_fcnn.add(Conv2DTranspose(256,(3,3),strides=(2,2),padding='same',activation='relu'))\n",
    "model_fcnn.add(Conv2D(3,(3,3),strides=(1,1),padding='same',activation='softmax'))\n",
    "    \n",
    "    #Classfication layer\n",
    "\n",
    "model_fcnn.summary()\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model_fcnn.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_1_array=img_1_array.astype('float32')/255\n",
    "history=model_fcnn.fit(img_1_array,img_1_array , batch_size=32, epochs=50,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model   \n",
    "#model_fcnn=load_model('fcnn.h5')\n",
    "n=0\n",
    "for im in img_1_array:\n",
    "    #im = cv2.imread('diease/01cff44f-9564-42f7-9a29-3daa487b306a___RS_L.Scorch 1333.JPG')\n",
    "    #im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "    #im=im.astype('float32')/255\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "    imOut=im.copy()\n",
    "    im=im.astype('float32')/255\n",
    "\n",
    "    im=im.reshape(-1,128,128,3)\n",
    "    pred=model_fcnn.predict(im)\n",
    "\n",
    "    #print(pred)\n",
    "    #原本顏色太暗所以條遺下\n",
    "    pred=pred.astype('float32')\n",
    "    #plt.subplot(2,2,2)\n",
    "    #plt.imshow(cv2.cvtColor(pred[0],cv2.COLOR_BGR2RGB))\n",
    "    #mask=np.zeros((128,128),dtype=np.uint8)\n",
    "    for x in  range(128):\n",
    "        for y in range(128):\n",
    "            if(pred[0][x][y][1]>0.3):   \n",
    "                pred[0][x][y]=(0,0,0)\n",
    "            else:\n",
    "                imOut[x][y]=(0,0,255)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(cv2.cvtColor(imOut,cv2.COLOR_BGR2RGB))            \n",
    "    #print(pred)\n",
    "    #pred=pred.astype('float32')\n",
    "    #pred=cv2.cvtColor(pred.reshape(128,128,3),cv2.COLOR_BGR2RGB)\n",
    "    #plt.subplot(2,2,2)\n",
    "    #plt.imshow(pred)\n",
    "    #plt.subplot(2,2,3)\n",
    "    #plt.imshow(mask,cmap='gray')\n",
    "    #print(imOut.dtype)\n",
    "    \n",
    "    #ret,mask = cv2.threshold(mask,55,255,cv2.THRESH_BINARY)\n",
    "    #print(mask.dtype)\n",
    "    #im_res= cv2.bitwise_and(imOut,imOut, mask= mask)\n",
    "    #plt.subplot(2,2,4)\n",
    "    \n",
    "    #plt.imshow(cv2.cvtColor(im_res,cv2.COLOR_BGR2RGB))       \n",
    "    plt.show()\n",
    "    #cv2.imwrite('cnn_diease/cnn_diease_{}.jpg'.format(n),im_res)\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_fcnn.save('fcnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in img_1_array[:1]:\n",
    "    # 建立 Selective Search 分割器\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "    # 設定要進行分割的圖形\n",
    "    ss.setBaseImage(im)\n",
    "\n",
    "    # 使用快速模式（精準度較差）\n",
    "    #ss.switchToSelectiveSearchFast()\n",
    "\n",
    "    # 使用精準模式（速度較慢）\n",
    "    ss.switchToSelectiveSearchQuality()\n",
    "\n",
    "    # 執行 Selective Search 分割\n",
    "    rects = ss.process()\n",
    "\n",
    "    print('候選區域總數量： {}'.format(len(rects)))\n",
    "\n",
    "    # 要顯示的候選區域數量\n",
    "    numShowRects = 50\n",
    "\n",
    "    # 每次增加或減少顯示的候選區域數量\n",
    "    increment = 50\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    im=im.astype('float32')/255\n",
    "\n",
    "    im=im.reshape(-1,128,128,3)\n",
    "    pred=model_fcnn.predict(im)\n",
    "\n",
    "    #print(pred)\n",
    "    #原本顏色太暗所以條遺下\n",
    "    pred=pred.astype('float32')\n",
    "    \n",
    "    #for x in  range(128):\n",
    "    #    for y in range(128):\n",
    "    \n",
    "    #        pred[0][x][y][1]=\n",
    "    #print(pred)\n",
    "    #pred=pred.astype('float32')\n",
    "    pred=cv2.cvtColor(pred.reshape(128,128,3),cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(pred)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  # 以迴圈處理每一個候選區域\n",
    "    for i, rect in enumerate(rects):\n",
    "      # 以方框標示候選區域\n",
    "\n",
    "        if (i < numShowRects):\n",
    "            imOut = im[0].copy()\n",
    "            x, y, w, h = rect\n",
    "            imrect=pred[y:y+h,x:x+w]\n",
    "            print(imrect.shape)\n",
    "            print(rect)\n",
    "            imrect=cv2.resize(imrect,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(imrect)\n",
    "            imrect=imrect.reshape(-1,128,128,3)\n",
    "            pred=model.predict(imrect)\n",
    "            if(np.argmax(pred)==0):\n",
    "\n",
    "                cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 0, 1), 1, cv2.LINE_AA)\n",
    "                imOut=imOut.astype('float32')\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.imshow(cv2.cvtColor(imOut,cv2.COLOR_BGR2RGB))\n",
    "            plt.show()\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train.astype('float32')/255\n",
    "img_test=img_test.astype('float32')/255\n",
    "\n",
    "model_Conv2DTranspose = Sequential()\n",
    "  \n",
    "\n",
    "#test\n",
    "\n",
    "model_Conv2DTranspose.add(Conv2D(96, kernel_size=(3, 3),strides=(2,2), activation='relu', kernel_initializer='he_normal',padding='same', input_shape=(128,128,3)))\n",
    "#model_Conv2DTranspose.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal',padding='same'))\n",
    "#model_Conv2DTranspose.add(Conv2D(16, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(16, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal',padding='same'))\n",
    "model_Conv2DTranspose.add(Conv2DTranspose(3, kernel_size=(3,3),strides=(2,2), activation='relu', kernel_initializer='he_normal',padding='same'))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " #First Convolution and Pooling layer\n",
    "#model_Conv2DTranspose.add(Conv2D(80,(3,3),strides=(2,2),input_shape=(128,128,3),padding='same',activation='relu', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same'))\n",
    "  \n",
    "\n",
    "  \n",
    "    #Second Convolution and Pooling layer\n",
    "#model_Conv2DTranspose.add(Conv2D(32,(3,3),strides=(2,2),padding='same',activation='relu', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same'))\n",
    "    \n",
    "\n",
    "    #Three Convolution layer and Pooling Layer\n",
    "#model_Conv2DTranspose.add(Conv2D(16,(3,3),strides=(2,2),padding='same',activation='relu', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(Conv2D(32,(3,3),strides=(1,1),activation='relu'))\n",
    "#model_Conv2DTranspose.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu'))\n",
    "#model_Conv2DTranspose.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same'))\n",
    "\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(16,kernel_size=(3, 3), strides=(2,2), activation='relu',padding='same', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(32,kernel_size=(3, 3),padding='same', strides=(2,2), activation='relu', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(64,kernel_size=(3, 3),padding='same', strides=(2,2), activation='relu', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(32,kernel_size=(3, 3),padding='same', strides=(2,2), activation='relu', kernel_initializer='he_uniform'))\n",
    "#model_Conv2DTranspose.add(Conv2DTranspose(3,kernel_size=(3, 3), strides=(2,2), activation='sigmoid', kernel_initializer='he_uniform',padding='same'))\n",
    "\n",
    "model_Conv2DTranspose.summary()\n",
    "#weights = [np.asarray([[[[1]]]]), np.asarray([0])]\n",
    "# store the weights in the model\n",
    "#model_Conv2DTranspose.set_weights(weights)\n",
    "model_Conv2DTranspose.compile(optimizer='adam', loss=objective, metrics=['accuracy'])\n",
    "model_Conv2DTranspose.fit(img_train, img_train, batch_size=64, epochs=10,shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((model_Conv2DTranspose.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in img_1_array:\n",
    "    #im = cv2.imread('diease/01cff44f-9564-42f7-9a29-3daa487b306a___RS_L.Scorch 1333.JPG')\n",
    "    #im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "    im=im.astype('float32')/255\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(cv2.cvtColor(im,cv2.COLOR_BGR2RGB))\n",
    "    #plt.show()\n",
    "    \n",
    "    im=im.reshape(-1,128,128,3)\n",
    "    pred=model_Conv2DTranspose.predict(im)\n",
    "\n",
    "    #print(pred)\n",
    "    pred=pred.astype('float32')\n",
    "    #for x in  range(128):\n",
    "    #    for y in range(128):\n",
    "    \n",
    "    #        pred[0][x][y]=np.argmax(pred[0][x][y])\n",
    "    #print(pred)\n",
    "    #pred=pred.astype('float32')\n",
    "    pred=cv2.cvtColor(pred.reshape(128,128,3),cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-tf-venv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
